{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495ba759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PreProcessor as pp\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Embedding, Dense, LayerNormalization, Dropout, Softmax, concatenate, Add\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b09c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of channels   : 12 \n",
      "Number of notes      : 105 \n",
      "Number of velocities : 128 \n",
      "Time range           : 0.0 190.285\n"
     ]
    }
   ],
   "source": [
    "dataset = pp.load_dataset(\"../adl-piano-midi\")\n",
    "ClassicSongs = pp.files_to_songs(dataset[\"Classical\"])\n",
    "\n",
    "channel_to_ind, ind_to_channel, note_to_ind, ind_to_note, velocity_to_ind, ind_to_velocity = pp.dicts_from_songs(ClassicSongs)\n",
    "time_range = pp.ranges_from_songs(ClassicSongs)\n",
    "\n",
    "n_Channels = len(channel_to_ind)\n",
    "n_Notes = len(note_to_ind)\n",
    "n_Velocities = len(velocity_to_ind)\n",
    "\n",
    "print(\"\\nNumber of channels   :\",n_Channels,\"\\nNumber of notes      :\",n_Notes,\"\\nNumber of velocities :\",n_Velocities,\"\\nTime range           :\",time_range[0],time_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988dc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_Channels, n_Notes, n_Velocities, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        tot_dim = n_Channels + n_Notes + n_Velocities\n",
    "        self.d_Channels = int((d_model-1)*n_Channels/tot_dim)\n",
    "        self.d_Notes = int((d_model-1)*n_Notes/tot_dim)\n",
    "        self.d_Velocities = int((d_model-1)*n_Velocities/tot_dim)\n",
    "        while self.d_Channels + self.d_Notes + self.d_Velocities != d_model - 1 : self.d_Channels += 1\n",
    "            \n",
    "        self.Channel_Embedding = Embedding(n_Channels, self.d_Channels)\n",
    "        self.Notes_Embedding = Embedding(n_Notes, self.d_Notes)\n",
    "        self.Velocities_Embedding = Embedding(n_Velocities, self.d_Velocities)\n",
    "\n",
    "    def call(self, x):\n",
    "        chan = self.Channel_Embedding(x[0])\n",
    "        note = self.Notes_Embedding(x[1])\n",
    "        velo = self.Velocities_Embedding(x[2])\n",
    "        \n",
    "        # Scale to values between 0 and 1 ? (/time_range[1])\n",
    "        time = tf.expand_dims(x[3],-1)\n",
    "        return concatenate([chan,note,velo,time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dea01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, seq_length):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.pos_encoding = self.positional_encoding(seq_length, d_model)\n",
    "        \n",
    "    def positional_encoding(self, length, depth):\n",
    "        depth = depth/2\n",
    "\n",
    "        positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "        depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "        angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "        angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "        pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)],axis=-1) \n",
    "\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)[tf.newaxis, :, :]\n",
    "\n",
    "    def call(self, x):\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float64))\n",
    "        return x + self.pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16f01b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(tf.keras.layers.Layer):\n",
    "    # Dropout ??\n",
    "    def __init__(self, num_heads, d_model, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads, d_model, **kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query=x,value=x,key=x,use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18b75571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(dff, activation='relu'),\n",
    "          tf.keras.layers.Dense(d_model),\n",
    "          tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_heads,dff,dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention_block = SelfAttentionBlock(num_heads,d_model)\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attention_block(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eabfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_Channels, n_Notes, n_Velocities, seq_length, d_model, n_layers, n_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = MusicEmbedding(n_Channels, n_Notes, n_Velocities, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8332d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.1498716  -0.85612124 -1.1648456  -1.1308112  -0.87213653\n",
      "   -1.1369947  -0.7647081  -0.43588072  0.02077937 -0.97929984\n",
      "   -1.3925036  -1.247667   -1.9367722   0.43962714 -0.81963825\n",
      "   -0.95911884 -1.556759   -0.26435328 -0.23319872  0.09209898\n",
      "   -0.08885338 -0.23668104 -1.6400095  -1.5634454  -1.3997375\n",
      "    1.0864894  -0.2863794   0.92640597  1.3242077   1.0166073\n",
      "    0.07095198  1.4390601   1.118162    0.57787865  0.35616288\n",
      "    0.6363855   0.13609928  1.281493    0.5349418   0.44104514\n",
      "    0.87509614  0.48874077  1.2036344   1.3760026   0.145619\n",
      "    0.85943335  0.02686546  1.1155527   2.3972974   0.82940584]\n",
      "  [ 1.4470997   0.22542562 -0.4687415  -0.56804615 -0.5025308\n",
      "   -1.1563098  -1.0686269  -0.5042613   0.03162462 -0.71868485\n",
      "   -1.224994   -1.6646316  -1.5910096   0.09239317 -1.4874991\n",
      "   -1.3530526  -1.5160458  -0.6443248  -0.68528724 -0.1939443\n",
      "   -0.1922605  -0.45660013 -1.9647781  -1.1683023  -1.5229385\n",
      "    0.86588293 -0.1301964   0.5302467   1.4896765   0.81835943\n",
      "    0.01007496  1.5686082   1.0719899   0.15059465  0.7645244\n",
      "    0.7747681   0.48221457  1.3356923   0.59255314  0.1278332\n",
      "    1.0584675   0.49100462  1.280841    1.3737491   0.36319494\n",
      "    0.6670401  -0.0687001   1.3938825   1.8297112   0.01431393]\n",
      "  [ 1.0346886   0.90690535 -0.28988138 -0.01589008 -0.7348277\n",
      "   -0.63521147 -1.0561725   0.02243763 -0.26069382 -0.708667\n",
      "   -1.1730982  -1.5300446  -2.0510216   0.4979748  -1.2627872\n",
      "   -1.4371058  -1.1121794  -0.52150494 -0.94323707 -0.07039136\n",
      "    0.32322887 -0.8653013  -1.7941564  -0.6737322  -0.919361\n",
      "   -1.1526006  -1.1267366   0.27858233  0.9090741   0.7824828\n",
      "    0.13640629  1.448827    0.6130728   0.15791042  0.3278445\n",
      "    0.9289885   0.46458122  1.6130844   0.43350315 -0.19309272\n",
      "    0.7068515  -0.06718878  1.0292131   1.0228534   0.58477867\n",
      "    0.33730385  0.5521088   1.0166194   1.6284673   2.8370948 ]\n",
      "  [-0.23396555  0.8142946   0.18897554  0.3376689   0.42864427\n",
      "   -0.69192004 -0.7277892   0.12797545 -0.02881095 -0.52371657\n",
      "   -0.78771234 -1.1336373  -1.938166    0.15839112 -1.4212589\n",
      "   -1.6018149  -1.1013283  -0.66324353 -1.7251581  -0.25754258\n",
      "    0.27341083 -0.7369252  -1.78988    -0.1747548  -0.7306787\n",
      "   -1.9529976  -2.103083   -0.35399824  0.7559771   0.7713535\n",
      "    0.33769438  1.4230493   0.75469023  0.0149087   0.4828898\n",
      "    1.2243385   0.3520433   1.955792    0.8137494   0.4502127\n",
      "    1.1288733   0.5869379   1.4460521   0.83622366  0.8128465\n",
      "    0.40926313  0.749192    1.1507035   1.4746716   0.41755888]]], shape=(1, 4, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "chan = np.array([[1,2,2,0]],dtype=int)\n",
    "note = np.array([[0,54,78,39]],dtype=int)\n",
    "velo = np.array([[127,0,32,49]],dtype=int)\n",
    "time = np.array([[0.541,0.0236,1.754,0.0416]])\n",
    "\n",
    "dim = 50\n",
    "seq_length = 4\n",
    "n_heads = 2\n",
    "\n",
    "musEmb = MusicEmbedding(n_Channels, n_Notes, n_Velocities, dim)\n",
    "posEnc = PositionalEncoding(dim, seq_length)\n",
    "selAtt = SelfAttentionBlock(n_heads,dim)\n",
    "fedFor = FeedForward(dim,4*dim)\n",
    "\n",
    "x = musEmb.call([chan,note,velo,time])\n",
    "y = posEnc.call(x)\n",
    "z = selAtt.call(y)\n",
    "o = fedFor.call(o)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15964c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
