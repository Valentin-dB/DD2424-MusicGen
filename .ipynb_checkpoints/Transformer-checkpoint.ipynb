{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b2cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PreProcessor as pp\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, Softmax, concatenate\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f13769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of channels   : 12 \n",
      "Number of notes      : 105 \n",
      "Number of velocities : 128 \n",
      "Time range           : 0.0 190.285\n"
     ]
    }
   ],
   "source": [
    "dataset = pp.load_dataset(\"../adl-piano-midi\")\n",
    "ClassicSongs = pp.files_to_songs(dataset[\"Classical\"])\n",
    "\n",
    "channel_to_ind, ind_to_channel, note_to_ind, ind_to_note, velocity_to_ind, ind_to_velocity = pp.dicts_from_songs(ClassicSongs)\n",
    "time_range = pp.ranges_from_songs(ClassicSongs)\n",
    "\n",
    "n_Channels = len(channel_to_ind)\n",
    "n_Notes = len(note_to_ind)\n",
    "n_Velocities = len(velocity_to_ind)\n",
    "\n",
    "print(\"\\nNumber of channels   :\",n_Channels,\"\\nNumber of notes      :\",n_Notes,\"\\nNumber of velocities :\",n_Velocities,\"\\nTime range           :\",time_range[0],time_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4837af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_Channels, n_Notes, n_Velocities, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        tot_dim = n_Channels + n_Notes + n_Velocities\n",
    "        self.d_Channels = np.floor((d_model-1)*n_Channels/tot_dim)\n",
    "        self.d_Notes = np.floor((d_model-1)*n_Notes/tot_dim)\n",
    "        self.d_Velocities = np.floor((d_model-1)*n_Velocities/tot_dim)\n",
    "        while self.d_Channels + self.d_Notes + self.d_Velocities != d_model - 1 : self.d_Channels += 1\n",
    "            \n",
    "        self.Channel_Embedding = Embedding(n_Channels, self.d_Channels)\n",
    "        self.Notes_Embedding = Embedding(n_Notes, self.d_Notes)\n",
    "        self.Velocities_Embedding = Embedding(n_Velocities, self.d_Velocities)\n",
    "\n",
    "    def call(self, x):\n",
    "        chan = self.Channel_Embedding(x[:,:,0])\n",
    "        note = self.Notes_Embedding(x[:,:,1])\n",
    "        velo = self.Velocities_Embedding(x[:,:,2])\n",
    "        time = x[:,:,3:]\n",
    "        return concatenate([chan,note,velo,time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b04911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, seq_length):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.pos_encoding = self.positional_encoding(seq_length, d_model)\n",
    "        \n",
    "    def positional_encoding(self, length, depth):\n",
    "        depth = depth/2\n",
    "\n",
    "        positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "        depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "        angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "        angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "        pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)],axis=-1) \n",
    "\n",
    "        return tf.cast(pos_encoding, dtype=tf.float64)[tf.newaxis, :, :]\n",
    "\n",
    "    def call(self, x):\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float64))\n",
    "        return x + self.pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306be83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
